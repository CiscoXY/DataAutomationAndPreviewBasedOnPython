[toc]

# 课题简介

现如今，随着大数据和人工智能在各个行业的广泛应用，对数据的处理也愈加频繁和深入。
作为研究、挖掘数据之中价值的统计学，其地位也愈发重要。但同时，由于数据的不规范和特异性，每次在处理数据的时候不仅仅需要做数据清洗和预处理，还需要通过各种手段和统计方法把握数据的特征和各种指标。
随之而来的，便是人们在应用统计模型、机器学习系列模型时，最消耗时间的不是选择和优化模型，反而是针对数据的处理和理解。
在任何有关数据的统计研究、机器学习项目的生命周期中，我们在数据分析、特征选择、特征工程等环节耗费时间占整个项目的 60% 的以上，一方面它是数据科学项目中最重要的部分，另一方面它是必须要进行的，比如清理数据、处理缺失值、处理异常值、处理不平衡的数据集、等等。因此高效完成这一部分势在必行。

但是，主流的统计软件和程序，在面对数据初步处理和把握的时候，都需要花费时间进行代码的撰写亦或是鼠标的点击和关联。步骤繁琐，容易出现bug。即使是较为简单的代码，实现某一个较小的功能也需要几行代码。一旦数据的复杂度和操作量增加，积少成多积水成渊，便是极大的时间消耗量。

正因如此，实现对数据的自动化预览和初步自动化处理便尤为重要。本课题基于python实现对数据的自动化整理和较为全面初步的预览分析。

现如今市面上无论是R语言还是python，实现数据自动化预览和处理的库都较少，虽然可以较大节省时间，但仍然停留在描述性统计及其类似分析的层面上。例如python中的：dtale；pandas profiling；sweetviz；autoviz

这四个顶级python库都是较为粗浅的对数据进行概览，而不涉及相对深入的分析。但是很显然，“异常值”许多时候并非是只有一维数据才有，二维数据的“异常值”就不是简单地可以用一维数据的鉴定方法可以甄别的，而是需要例如回归分析中库克距离这类的甄别方法。由此可见市面上并未出现相对深入而完全的数据概览方式。

本课题基于这些需求和现如今的解决方案，提出了更具有通用性，快捷性，深入的解决方案：“基于python的自动化处理预览方案”

# 主要研究学科和方向
主要研究学科：统计学
辅助工具：计算机科学与技术（基于python）
该课题主要涉及内容：
1.数据清洗和预处理
2.描述性统计
3.回归分析
4.多元统计分析
5.非参数统计方法的应用
6.用户图形界面和程序相关

方向：利用python将各种统计方法进行自动化编程和封装，具有较强的一般性和通用性的同时可应对多种异常情况。

# 工作计划

注：相应工作和项目规划已经上传到github公开库：https://github.com/CiscoXY/Graduation-Project-Of-Undergraduate

由于我需要考研，所以在复试结束之前，每天大约有2-3小时的工作时间，一周约为12小时。
2-3月：完成大概框架的构想和分析模块的初步撰写
3-3月中旬：完成数据清洗，整理，预处理模块
3月中旬-4月：完成并完善数据模块和描述性统计模块
4月-4月中旬：完善所有模块的串联和bug剔除。
4月中旬-5月：完成GUI的编写，并将所有功能以GUI形式呈现。同时完善API的封装和调用测试
5月-5.10号前后：完成论文的初稿。

# 文献检索总述：

该课题涉及文献有：
统计学相关书籍；
细节的统计学方法对应的论文，例如蒙特卡洛相关算法的实现的论文；
各大python第三方库官方文档
数据自动化处理相关期刊和论文
